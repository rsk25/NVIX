{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from bertviz import head_view\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.swan import SWANPhase1Only\n",
    "from model.base import chkpt\n",
    "from test_model import load_config, run_model_for_attention\n",
    "from common.dataset import Dataset\n",
    "from learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = Path('.')\n",
    "data_path = main_path / 'resource'\n",
    "chpt_path = main_path / 'runs_copy' / 'best_SWAN_P1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torch.load(chpt_path / 'tokenizer.pt')\n",
    "checkpoint = torch.load(chpt_path / 'SWANPhase1Only.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraModel were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['electra.encoder.layer.2.crossattention.self.query.bias', 'electra.encoder.layer.5.crossattention.self.query.weight', 'electra.encoder.layer.3.crossattention.output.dense.bias', 'electra.encoder.layer.6.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.5.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.4.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.3.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.7.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.2.crossattention.self.key.bias', 'electra.encoder.layer.7.crossattention.output.dense.weight', 'electra.encoder.layer.0.crossattention.self.value.bias', 'electra.encoder.layer.8.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.1.crossattention.self.value.weight', 'electra.encoder.layer.8.crossattention.self.key.bias', 'electra.encoder.layer.4.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.0.crossattention.self.value.weight', 'electra.encoder.layer.0.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.3.crossattention.self.value.weight', 'electra.encoder.layer.0.crossattention.self.key.weight', 'electra.encoder.layer.10.crossattention.self.value.weight', 'electra.encoder.layer.6.crossattention.self.query.bias', 'electra.encoder.layer.10.crossattention.output.dense.weight', 'electra.encoder.layer.11.crossattention.self.query.bias', 'electra.encoder.layer.3.crossattention.self.key.bias', 'electra.encoder.layer.1.crossattention.self.value.bias', 'electra.encoder.layer.4.crossattention.output.dense.weight', 'electra.encoder.layer.0.crossattention.output.dense.bias', 'electra.encoder.layer.3.crossattention.output.dense.weight', 'electra.encoder.layer.4.crossattention.self.value.bias', 'electra.encoder.layer.5.crossattention.self.key.bias', 'electra.encoder.layer.2.crossattention.self.query.weight', 'electra.encoder.layer.5.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.9.crossattention.self.value.weight', 'electra.encoder.layer.8.crossattention.self.key.weight', 'electra.encoder.layer.11.crossattention.self.value.bias', 'electra.encoder.layer.11.crossattention.self.key.weight', 'electra.encoder.layer.7.crossattention.self.query.bias', 'electra.encoder.layer.5.crossattention.self.query.bias', 'electra.encoder.layer.3.crossattention.self.query.bias', 'electra.encoder.layer.7.crossattention.self.value.weight', 'electra.encoder.layer.9.crossattention.self.key.bias', 'electra.encoder.layer.2.crossattention.self.value.bias', 'electra.encoder.layer.9.crossattention.output.dense.weight', 'electra.encoder.layer.8.crossattention.self.query.bias', 'electra.encoder.layer.8.crossattention.self.value.bias', 'electra.encoder.layer.6.crossattention.self.key.weight', 'electra.encoder.layer.9.crossattention.self.query.weight', 'electra.encoder.layer.9.crossattention.self.key.weight', 'electra.encoder.layer.1.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.7.crossattention.output.dense.bias', 'electra.encoder.layer.6.crossattention.output.dense.bias', 'electra.encoder.layer.1.crossattention.output.dense.bias', 'electra.encoder.layer.8.crossattention.self.value.weight', 'electra.encoder.layer.11.crossattention.self.value.weight', 'electra.encoder.layer.10.crossattention.self.query.bias', 'electra.encoder.layer.8.crossattention.self.query.weight', 'electra.encoder.layer.1.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.4.crossattention.self.query.bias', 'electra.encoder.layer.7.crossattention.self.key.bias', 'electra.encoder.layer.10.crossattention.self.value.bias', 'electra.encoder.layer.11.crossattention.self.key.bias', 'electra.encoder.layer.11.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.10.crossattention.self.query.weight', 'electra.encoder.layer.6.crossattention.self.query.weight', 'electra.encoder.layer.4.crossattention.self.key.weight', 'electra.encoder.layer.5.crossattention.self.key.weight', 'electra.encoder.layer.3.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.1.crossattention.self.key.weight', 'electra.encoder.layer.4.crossattention.self.value.weight', 'electra.encoder.layer.2.crossattention.self.value.weight', 'electra.encoder.layer.9.crossattention.self.query.bias', 'electra.encoder.layer.5.crossattention.self.value.weight', 'electra.encoder.layer.8.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.1.crossattention.self.key.bias', 'electra.encoder.layer.3.crossattention.self.key.weight', 'electra.encoder.layer.7.crossattention.self.query.weight', 'electra.encoder.layer.4.crossattention.self.key.bias', 'electra.encoder.layer.9.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.8.crossattention.output.dense.weight', 'electra.encoder.layer.0.crossattention.self.key.bias', 'electra.encoder.layer.11.crossattention.self.query.weight', 'electra.encoder.layer.11.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.1.crossattention.output.dense.weight', 'electra.encoder.layer.0.crossattention.self.query.weight', 'electra.encoder.layer.6.crossattention.self.key.bias', 'electra.encoder.layer.6.crossattention.self.value.bias', 'electra.encoder.layer.7.crossattention.self.value.bias', 'electra.encoder.layer.9.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.1.crossattention.self.query.bias', 'electra.encoder.layer.0.crossattention.output.dense.weight', 'electra.encoder.layer.10.crossattention.output.dense.bias', 'electra.encoder.layer.2.crossattention.output.dense.weight', 'electra.encoder.layer.9.crossattention.self.value.bias', 'electra.encoder.layer.11.crossattention.output.dense.weight', 'electra.encoder.layer.10.crossattention.self.key.weight', 'electra.encoder.layer.2.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.7.crossattention.self.key.weight', 'electra.encoder.layer.1.crossattention.self.query.weight', 'electra.encoder.layer.2.crossattention.self.key.weight', 'electra.encoder.layer.4.crossattention.self.query.weight', 'electra.encoder.layer.7.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.11.crossattention.output.dense.bias', 'electra.encoder.layer.10.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.10.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.6.crossattention.output.dense.weight', 'electra.encoder.layer.9.crossattention.output.dense.bias', 'electra.encoder.layer.6.crossattention.self.value.weight', 'electra.encoder.layer.3.crossattention.self.value.bias', 'electra.encoder.layer.5.crossattention.output.dense.bias', 'electra.encoder.layer.6.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.0.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.4.crossattention.output.dense.bias', 'electra.encoder.layer.2.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.8.crossattention.output.dense.bias', 'electra.encoder.layer.5.crossattention.self.value.bias', 'electra.encoder.layer.3.crossattention.self.query.weight', 'electra.encoder.layer.2.crossattention.output.dense.bias', 'electra.encoder.layer.5.crossattention.output.dense.weight', 'electra.encoder.layer.0.crossattention.self.query.bias', 'electra.encoder.layer.10.crossattention.self.key.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SWANPhase1Only(\n",
       "  (encoder): TextEncoder(\n",
       "    (model): ElectraModel(\n",
       "      (embeddings): ElectraEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): ElectraEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): ElectraLayer(\n",
       "            (attention): ElectraAttention(\n",
       "              (self): ElectraSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): ElectraSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ElectraIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ElectraOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (equation): EquationDecoder(\n",
       "    (operator_word_embedding): Embedding(9, 768)\n",
       "    (operator_pos_embedding): PositionalEncoding()\n",
       "    (operand_source_embedding): Embedding(3, 768)\n",
       "    (constant_word_embedding): Embedding(23, 768)\n",
       "    (operator_norm): MaskedLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (operand_norm): MaskedLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (embed_to_hidden): Linear(in_features=2304, out_features=768, bias=True)\n",
       "    (shared_decoder_layer): TransformerLayer(\n",
       "      (attn): MultiheadAttention(\n",
       "        (attn): MultiheadAttentionWeights(\n",
       "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (mem): MultiheadAttention(\n",
       "        (attn): MultiheadAttentionWeights(\n",
       "          (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (linear_out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (lin_expand): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (lin_collapse): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (gelu): GELU()\n",
       "      (norm_attn): MaskedLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (norm_mem): MaskedLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (norm_out): MaskedLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (operator): Linear(in_features=768, out_features=9, bias=True)\n",
       "  (operands): ModuleList(\n",
       "    (0): ModuleDict(\n",
       "      (0_attn): MultiheadAttentionWeights(\n",
       "        (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (1_mean): Squeeze(dim=-1)\n",
       "    )\n",
       "    (1): ModuleDict(\n",
       "      (0_attn): MultiheadAttentionWeights(\n",
       "        (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (1_mean): Squeeze(dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (explanation): ExplanationDecoder(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (explanation_pghead): PointerGeneratorHead(\n",
       "    (encoder_attention): MultiheadAttentionWeights(\n",
       "      (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (generation_dist): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    (generation_prob_linear): Linear(in_features=2304, out_features=1, bias=True)\n",
       "    (log_sigmoid): LogSigmoid()\n",
       "  )\n",
       "  (var_count_expand): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (var_count_predict): Linear(in_features=3072, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = load_config(chpt_path)\n",
    "nvix = SWANPhase1Only.create_or_load(path=str(chpt_path), **config)\n",
    "nvix.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = nvix.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explanation._prefix_number', 'explanation.embeddings.position_ids', 'explanation.embeddings.word_embeddings.weight', 'explanation.embeddings.position_embeddings.weight', 'explanation.embeddings.token_type_embeddings.weight', 'explanation.embeddings.LayerNorm.weight', 'explanation.embeddings.LayerNorm.bias', 'explanation.encoder.layer.0.attention.self.query.weight', 'explanation.encoder.layer.0.attention.self.query.bias', 'explanation.encoder.layer.0.attention.self.key.weight', 'explanation.encoder.layer.0.attention.self.key.bias', 'explanation.encoder.layer.0.attention.self.value.weight', 'explanation.encoder.layer.0.attention.self.value.bias', 'explanation.encoder.layer.0.attention.output.dense.weight', 'explanation.encoder.layer.0.attention.output.dense.bias', 'explanation.encoder.layer.0.attention.output.LayerNorm.weight', 'explanation.encoder.layer.0.attention.output.LayerNorm.bias', 'explanation.encoder.layer.0.crossattention.self.query.weight', 'explanation.encoder.layer.0.crossattention.self.query.bias', 'explanation.encoder.layer.0.crossattention.self.key.weight', 'explanation.encoder.layer.0.crossattention.self.key.bias', 'explanation.encoder.layer.0.crossattention.self.value.weight', 'explanation.encoder.layer.0.crossattention.self.value.bias', 'explanation.encoder.layer.0.crossattention.output.dense.weight', 'explanation.encoder.layer.0.crossattention.output.dense.bias', 'explanation.encoder.layer.0.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.0.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.0.intermediate.dense.weight', 'explanation.encoder.layer.0.intermediate.dense.bias', 'explanation.encoder.layer.0.output.dense.weight', 'explanation.encoder.layer.0.output.dense.bias', 'explanation.encoder.layer.0.output.LayerNorm.weight', 'explanation.encoder.layer.0.output.LayerNorm.bias', 'explanation.encoder.layer.1.attention.self.query.weight', 'explanation.encoder.layer.1.attention.self.query.bias', 'explanation.encoder.layer.1.attention.self.key.weight', 'explanation.encoder.layer.1.attention.self.key.bias', 'explanation.encoder.layer.1.attention.self.value.weight', 'explanation.encoder.layer.1.attention.self.value.bias', 'explanation.encoder.layer.1.attention.output.dense.weight', 'explanation.encoder.layer.1.attention.output.dense.bias', 'explanation.encoder.layer.1.attention.output.LayerNorm.weight', 'explanation.encoder.layer.1.attention.output.LayerNorm.bias', 'explanation.encoder.layer.1.crossattention.self.query.weight', 'explanation.encoder.layer.1.crossattention.self.query.bias', 'explanation.encoder.layer.1.crossattention.self.key.weight', 'explanation.encoder.layer.1.crossattention.self.key.bias', 'explanation.encoder.layer.1.crossattention.self.value.weight', 'explanation.encoder.layer.1.crossattention.self.value.bias', 'explanation.encoder.layer.1.crossattention.output.dense.weight', 'explanation.encoder.layer.1.crossattention.output.dense.bias', 'explanation.encoder.layer.1.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.1.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.1.intermediate.dense.weight', 'explanation.encoder.layer.1.intermediate.dense.bias', 'explanation.encoder.layer.1.output.dense.weight', 'explanation.encoder.layer.1.output.dense.bias', 'explanation.encoder.layer.1.output.LayerNorm.weight', 'explanation.encoder.layer.1.output.LayerNorm.bias', 'explanation.encoder.layer.2.attention.self.query.weight', 'explanation.encoder.layer.2.attention.self.query.bias', 'explanation.encoder.layer.2.attention.self.key.weight', 'explanation.encoder.layer.2.attention.self.key.bias', 'explanation.encoder.layer.2.attention.self.value.weight', 'explanation.encoder.layer.2.attention.self.value.bias', 'explanation.encoder.layer.2.attention.output.dense.weight', 'explanation.encoder.layer.2.attention.output.dense.bias', 'explanation.encoder.layer.2.attention.output.LayerNorm.weight', 'explanation.encoder.layer.2.attention.output.LayerNorm.bias', 'explanation.encoder.layer.2.crossattention.self.query.weight', 'explanation.encoder.layer.2.crossattention.self.query.bias', 'explanation.encoder.layer.2.crossattention.self.key.weight', 'explanation.encoder.layer.2.crossattention.self.key.bias', 'explanation.encoder.layer.2.crossattention.self.value.weight', 'explanation.encoder.layer.2.crossattention.self.value.bias', 'explanation.encoder.layer.2.crossattention.output.dense.weight', 'explanation.encoder.layer.2.crossattention.output.dense.bias', 'explanation.encoder.layer.2.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.2.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.2.intermediate.dense.weight', 'explanation.encoder.layer.2.intermediate.dense.bias', 'explanation.encoder.layer.2.output.dense.weight', 'explanation.encoder.layer.2.output.dense.bias', 'explanation.encoder.layer.2.output.LayerNorm.weight', 'explanation.encoder.layer.2.output.LayerNorm.bias', 'explanation.encoder.layer.3.attention.self.query.weight', 'explanation.encoder.layer.3.attention.self.query.bias', 'explanation.encoder.layer.3.attention.self.key.weight', 'explanation.encoder.layer.3.attention.self.key.bias', 'explanation.encoder.layer.3.attention.self.value.weight', 'explanation.encoder.layer.3.attention.self.value.bias', 'explanation.encoder.layer.3.attention.output.dense.weight', 'explanation.encoder.layer.3.attention.output.dense.bias', 'explanation.encoder.layer.3.attention.output.LayerNorm.weight', 'explanation.encoder.layer.3.attention.output.LayerNorm.bias', 'explanation.encoder.layer.3.crossattention.self.query.weight', 'explanation.encoder.layer.3.crossattention.self.query.bias', 'explanation.encoder.layer.3.crossattention.self.key.weight', 'explanation.encoder.layer.3.crossattention.self.key.bias', 'explanation.encoder.layer.3.crossattention.self.value.weight', 'explanation.encoder.layer.3.crossattention.self.value.bias', 'explanation.encoder.layer.3.crossattention.output.dense.weight', 'explanation.encoder.layer.3.crossattention.output.dense.bias', 'explanation.encoder.layer.3.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.3.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.3.intermediate.dense.weight', 'explanation.encoder.layer.3.intermediate.dense.bias', 'explanation.encoder.layer.3.output.dense.weight', 'explanation.encoder.layer.3.output.dense.bias', 'explanation.encoder.layer.3.output.LayerNorm.weight', 'explanation.encoder.layer.3.output.LayerNorm.bias', 'explanation.encoder.layer.4.attention.self.query.weight', 'explanation.encoder.layer.4.attention.self.query.bias', 'explanation.encoder.layer.4.attention.self.key.weight', 'explanation.encoder.layer.4.attention.self.key.bias', 'explanation.encoder.layer.4.attention.self.value.weight', 'explanation.encoder.layer.4.attention.self.value.bias', 'explanation.encoder.layer.4.attention.output.dense.weight', 'explanation.encoder.layer.4.attention.output.dense.bias', 'explanation.encoder.layer.4.attention.output.LayerNorm.weight', 'explanation.encoder.layer.4.attention.output.LayerNorm.bias', 'explanation.encoder.layer.4.crossattention.self.query.weight', 'explanation.encoder.layer.4.crossattention.self.query.bias', 'explanation.encoder.layer.4.crossattention.self.key.weight', 'explanation.encoder.layer.4.crossattention.self.key.bias', 'explanation.encoder.layer.4.crossattention.self.value.weight', 'explanation.encoder.layer.4.crossattention.self.value.bias', 'explanation.encoder.layer.4.crossattention.output.dense.weight', 'explanation.encoder.layer.4.crossattention.output.dense.bias', 'explanation.encoder.layer.4.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.4.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.4.intermediate.dense.weight', 'explanation.encoder.layer.4.intermediate.dense.bias', 'explanation.encoder.layer.4.output.dense.weight', 'explanation.encoder.layer.4.output.dense.bias', 'explanation.encoder.layer.4.output.LayerNorm.weight', 'explanation.encoder.layer.4.output.LayerNorm.bias', 'explanation.encoder.layer.5.attention.self.query.weight', 'explanation.encoder.layer.5.attention.self.query.bias', 'explanation.encoder.layer.5.attention.self.key.weight', 'explanation.encoder.layer.5.attention.self.key.bias', 'explanation.encoder.layer.5.attention.self.value.weight', 'explanation.encoder.layer.5.attention.self.value.bias', 'explanation.encoder.layer.5.attention.output.dense.weight', 'explanation.encoder.layer.5.attention.output.dense.bias', 'explanation.encoder.layer.5.attention.output.LayerNorm.weight', 'explanation.encoder.layer.5.attention.output.LayerNorm.bias', 'explanation.encoder.layer.5.crossattention.self.query.weight', 'explanation.encoder.layer.5.crossattention.self.query.bias', 'explanation.encoder.layer.5.crossattention.self.key.weight', 'explanation.encoder.layer.5.crossattention.self.key.bias', 'explanation.encoder.layer.5.crossattention.self.value.weight', 'explanation.encoder.layer.5.crossattention.self.value.bias', 'explanation.encoder.layer.5.crossattention.output.dense.weight', 'explanation.encoder.layer.5.crossattention.output.dense.bias', 'explanation.encoder.layer.5.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.5.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.5.intermediate.dense.weight', 'explanation.encoder.layer.5.intermediate.dense.bias', 'explanation.encoder.layer.5.output.dense.weight', 'explanation.encoder.layer.5.output.dense.bias', 'explanation.encoder.layer.5.output.LayerNorm.weight', 'explanation.encoder.layer.5.output.LayerNorm.bias', 'explanation.encoder.layer.6.attention.self.query.weight', 'explanation.encoder.layer.6.attention.self.query.bias', 'explanation.encoder.layer.6.attention.self.key.weight', 'explanation.encoder.layer.6.attention.self.key.bias', 'explanation.encoder.layer.6.attention.self.value.weight', 'explanation.encoder.layer.6.attention.self.value.bias', 'explanation.encoder.layer.6.attention.output.dense.weight', 'explanation.encoder.layer.6.attention.output.dense.bias', 'explanation.encoder.layer.6.attention.output.LayerNorm.weight', 'explanation.encoder.layer.6.attention.output.LayerNorm.bias', 'explanation.encoder.layer.6.crossattention.self.query.weight', 'explanation.encoder.layer.6.crossattention.self.query.bias', 'explanation.encoder.layer.6.crossattention.self.key.weight', 'explanation.encoder.layer.6.crossattention.self.key.bias', 'explanation.encoder.layer.6.crossattention.self.value.weight', 'explanation.encoder.layer.6.crossattention.self.value.bias', 'explanation.encoder.layer.6.crossattention.output.dense.weight', 'explanation.encoder.layer.6.crossattention.output.dense.bias', 'explanation.encoder.layer.6.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.6.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.6.intermediate.dense.weight', 'explanation.encoder.layer.6.intermediate.dense.bias', 'explanation.encoder.layer.6.output.dense.weight', 'explanation.encoder.layer.6.output.dense.bias', 'explanation.encoder.layer.6.output.LayerNorm.weight', 'explanation.encoder.layer.6.output.LayerNorm.bias', 'explanation.encoder.layer.7.attention.self.query.weight', 'explanation.encoder.layer.7.attention.self.query.bias', 'explanation.encoder.layer.7.attention.self.key.weight', 'explanation.encoder.layer.7.attention.self.key.bias', 'explanation.encoder.layer.7.attention.self.value.weight', 'explanation.encoder.layer.7.attention.self.value.bias', 'explanation.encoder.layer.7.attention.output.dense.weight', 'explanation.encoder.layer.7.attention.output.dense.bias', 'explanation.encoder.layer.7.attention.output.LayerNorm.weight', 'explanation.encoder.layer.7.attention.output.LayerNorm.bias', 'explanation.encoder.layer.7.crossattention.self.query.weight', 'explanation.encoder.layer.7.crossattention.self.query.bias', 'explanation.encoder.layer.7.crossattention.self.key.weight', 'explanation.encoder.layer.7.crossattention.self.key.bias', 'explanation.encoder.layer.7.crossattention.self.value.weight', 'explanation.encoder.layer.7.crossattention.self.value.bias', 'explanation.encoder.layer.7.crossattention.output.dense.weight', 'explanation.encoder.layer.7.crossattention.output.dense.bias', 'explanation.encoder.layer.7.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.7.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.7.intermediate.dense.weight', 'explanation.encoder.layer.7.intermediate.dense.bias', 'explanation.encoder.layer.7.output.dense.weight', 'explanation.encoder.layer.7.output.dense.bias', 'explanation.encoder.layer.7.output.LayerNorm.weight', 'explanation.encoder.layer.7.output.LayerNorm.bias', 'explanation.encoder.layer.8.attention.self.query.weight', 'explanation.encoder.layer.8.attention.self.query.bias', 'explanation.encoder.layer.8.attention.self.key.weight', 'explanation.encoder.layer.8.attention.self.key.bias', 'explanation.encoder.layer.8.attention.self.value.weight', 'explanation.encoder.layer.8.attention.self.value.bias', 'explanation.encoder.layer.8.attention.output.dense.weight', 'explanation.encoder.layer.8.attention.output.dense.bias', 'explanation.encoder.layer.8.attention.output.LayerNorm.weight', 'explanation.encoder.layer.8.attention.output.LayerNorm.bias', 'explanation.encoder.layer.8.crossattention.self.query.weight', 'explanation.encoder.layer.8.crossattention.self.query.bias', 'explanation.encoder.layer.8.crossattention.self.key.weight', 'explanation.encoder.layer.8.crossattention.self.key.bias', 'explanation.encoder.layer.8.crossattention.self.value.weight', 'explanation.encoder.layer.8.crossattention.self.value.bias', 'explanation.encoder.layer.8.crossattention.output.dense.weight', 'explanation.encoder.layer.8.crossattention.output.dense.bias', 'explanation.encoder.layer.8.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.8.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.8.intermediate.dense.weight', 'explanation.encoder.layer.8.intermediate.dense.bias', 'explanation.encoder.layer.8.output.dense.weight', 'explanation.encoder.layer.8.output.dense.bias', 'explanation.encoder.layer.8.output.LayerNorm.weight', 'explanation.encoder.layer.8.output.LayerNorm.bias', 'explanation.encoder.layer.9.attention.self.query.weight', 'explanation.encoder.layer.9.attention.self.query.bias', 'explanation.encoder.layer.9.attention.self.key.weight', 'explanation.encoder.layer.9.attention.self.key.bias', 'explanation.encoder.layer.9.attention.self.value.weight', 'explanation.encoder.layer.9.attention.self.value.bias', 'explanation.encoder.layer.9.attention.output.dense.weight', 'explanation.encoder.layer.9.attention.output.dense.bias', 'explanation.encoder.layer.9.attention.output.LayerNorm.weight', 'explanation.encoder.layer.9.attention.output.LayerNorm.bias', 'explanation.encoder.layer.9.crossattention.self.query.weight', 'explanation.encoder.layer.9.crossattention.self.query.bias', 'explanation.encoder.layer.9.crossattention.self.key.weight', 'explanation.encoder.layer.9.crossattention.self.key.bias', 'explanation.encoder.layer.9.crossattention.self.value.weight', 'explanation.encoder.layer.9.crossattention.self.value.bias', 'explanation.encoder.layer.9.crossattention.output.dense.weight', 'explanation.encoder.layer.9.crossattention.output.dense.bias', 'explanation.encoder.layer.9.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.9.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.9.intermediate.dense.weight', 'explanation.encoder.layer.9.intermediate.dense.bias', 'explanation.encoder.layer.9.output.dense.weight', 'explanation.encoder.layer.9.output.dense.bias', 'explanation.encoder.layer.9.output.LayerNorm.weight', 'explanation.encoder.layer.9.output.LayerNorm.bias', 'explanation.encoder.layer.10.attention.self.query.weight', 'explanation.encoder.layer.10.attention.self.query.bias', 'explanation.encoder.layer.10.attention.self.key.weight', 'explanation.encoder.layer.10.attention.self.key.bias', 'explanation.encoder.layer.10.attention.self.value.weight', 'explanation.encoder.layer.10.attention.self.value.bias', 'explanation.encoder.layer.10.attention.output.dense.weight', 'explanation.encoder.layer.10.attention.output.dense.bias', 'explanation.encoder.layer.10.attention.output.LayerNorm.weight', 'explanation.encoder.layer.10.attention.output.LayerNorm.bias', 'explanation.encoder.layer.10.crossattention.self.query.weight', 'explanation.encoder.layer.10.crossattention.self.query.bias', 'explanation.encoder.layer.10.crossattention.self.key.weight', 'explanation.encoder.layer.10.crossattention.self.key.bias', 'explanation.encoder.layer.10.crossattention.self.value.weight', 'explanation.encoder.layer.10.crossattention.self.value.bias', 'explanation.encoder.layer.10.crossattention.output.dense.weight', 'explanation.encoder.layer.10.crossattention.output.dense.bias', 'explanation.encoder.layer.10.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.10.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.10.intermediate.dense.weight', 'explanation.encoder.layer.10.intermediate.dense.bias', 'explanation.encoder.layer.10.output.dense.weight', 'explanation.encoder.layer.10.output.dense.bias', 'explanation.encoder.layer.10.output.LayerNorm.weight', 'explanation.encoder.layer.10.output.LayerNorm.bias', 'explanation.encoder.layer.11.attention.self.query.weight', 'explanation.encoder.layer.11.attention.self.query.bias', 'explanation.encoder.layer.11.attention.self.key.weight', 'explanation.encoder.layer.11.attention.self.key.bias', 'explanation.encoder.layer.11.attention.self.value.weight', 'explanation.encoder.layer.11.attention.self.value.bias', 'explanation.encoder.layer.11.attention.output.dense.weight', 'explanation.encoder.layer.11.attention.output.dense.bias', 'explanation.encoder.layer.11.attention.output.LayerNorm.weight', 'explanation.encoder.layer.11.attention.output.LayerNorm.bias', 'explanation.encoder.layer.11.crossattention.self.query.weight', 'explanation.encoder.layer.11.crossattention.self.query.bias', 'explanation.encoder.layer.11.crossattention.self.key.weight', 'explanation.encoder.layer.11.crossattention.self.key.bias', 'explanation.encoder.layer.11.crossattention.self.value.weight', 'explanation.encoder.layer.11.crossattention.self.value.bias', 'explanation.encoder.layer.11.crossattention.output.dense.weight', 'explanation.encoder.layer.11.crossattention.output.dense.bias', 'explanation.encoder.layer.11.crossattention.output.LayerNorm.weight', 'explanation.encoder.layer.11.crossattention.output.LayerNorm.bias', 'explanation.encoder.layer.11.intermediate.dense.weight', 'explanation.encoder.layer.11.intermediate.dense.bias', 'explanation.encoder.layer.11.output.dense.weight', 'explanation.encoder.layer.11.output.dense.bias', 'explanation.encoder.layer.11.output.LayerNorm.weight', 'explanation.encoder.layer.11.output.LayerNorm.bias', 'explanation_pghead.encoder_attention.linear_q.weight', 'explanation_pghead.encoder_attention.linear_q.bias', 'explanation_pghead.encoder_attention.linear_k.weight', 'explanation_pghead.encoder_attention.linear_k.bias', 'explanation_pghead.generation_dist.weight', 'explanation_pghead.generation_dist.bias', 'explanation_pghead.generation_prob_linear.weight', 'explanation_pghead.generation_prob_linear.bias']\n"
     ]
    }
   ],
   "source": [
    "print([k for k in state_dict.keys() if \"explanation\" in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 3072])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['explanation.encoder.layer.11.output.dense.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['explanation.encoder.layer.11.attention.output.dense.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['explanation.encoder.layer.11.crossattention.output.dense.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['explanation.embeddings.LayerNorm.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = data_path / 'dataset' / 'pen.json'\n",
    "test_data = Dataset(dataset_file, number_window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.select_items_with_file(data_path / 'experiments'/ 'pen' /'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())\n"
     ]
    }
   ],
   "source": [
    "set_seed(config['seed'])\n",
    "batch = test_data.get_minibatches(batch_size=1, for_testing=True)\n",
    "output = nvix(\n",
    "    text=batch[0].text.to(nvix.device),\n",
    "    beam=config['beam_for_equation'], \n",
    "    beam_expl=config['beam_for_explanation']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3330e-01, 5.4100e-06, 1.4479e-06, 3.2128e-06, 1.9734e-07, 2.7834e-06,\n",
       "         4.6896e-08, 3.4509e-07, 1.9025e-06, 2.1453e-08, 1.1091e-06, 4.9619e-05,\n",
       "         7.8588e-06, 2.3247e-05, 4.8032e-06, 1.2212e-09, 3.3330e-01, 3.3330e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvix.explanation_pghead.attention_score[0] # Attention score: [B, T, S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvix.explanation_pghead.attention_score[0].shape # Attention score for single sample: [T, S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jeremy strolled 20 kilometers at 2 kilometers per hour . how long did jeremy stroll ?'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].text.raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].text.sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].text.as_dict()['raw'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].text.as_dict()['tokens'].shape # input token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded, num_out = nvix.encoder(batch[0].text)\n",
    "encoded.as_dict()['vector'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eqn_ignore': {1},\n",
       " 'var_expl': [Label([[102, 1996, 3091, 1997, 2051, 1997, 27244, 2075, 102, -1, -1, -1, -1]])],\n",
       " 'num_expl': [Label([[102, 1996, 3292, 1997, 27244, 2075, 1999, 7338, 102, -1, -1], [102, 1996, 3177, 1997, 27244, 2075, 1999, 7338, 2566, 3178, 102]])],\n",
       " 'explanation': [Explanation(numbers=$[Label([[102, 1996, 3292, 1997, 27244, 2075, 1999, 7338, 102, -1, -1], [102, 1996, 3177, 1997, 27244, 2075, 1999, 7338, 2566, 3178, 102]])], variables=$[Label([[102, 1996, 3091, 1997, 2051, 1997, 27244, 2075, 102, -1, -1, -1, -1]])], worker=$0)],\n",
       " 'equation': Equation(operator=Label([[0]]), operands=[Label([[-1]]), Label([[-1]])])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the distance of strolling in kilometers']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['explanation'][0].to_human_readable(tokenizer=tokenizer)['N_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 11])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['num_expl'][0].sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention, n_heads = 1, n_rows = 1, n_cols = 1):\n",
    "    \n",
    "    assert n_rows * n_cols == n_heads\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 25))\n",
    "    \n",
    "    for i in range(n_heads):\n",
    "        \n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        \n",
    "        _attention = attention.unsqueeze(0)[i].numpy()\n",
    "\n",
    "        cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                           rotation=45)\n",
    "        ax.set_yticklabels(['']+translation)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1005379/418651690.py:16: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'],\n",
      "/tmp/ipykernel_1005379/418651690.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(['']+translation)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "explanations = output['explanation'][0].to_human_readable(tokenizer=tokenizer)\n",
    "\n",
    "display_attention(sentence=batch[0].text.raw[0].split(), translation=explanations['N_00'][0].split(), attention=nvix.explanation_pghead.attention_score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the distance of strolling in kilometers'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations['N_00'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# http://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor\n",
    "def plot_head_map(mma, target_labels, source_labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(mma, cmap=plt.cm.Blues)\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(numpy.arange(mma.shape[1]) + 0.5, minor=False) # mma.shape[1] = target seq \n",
    "    ax.set_yticks(numpy.arange(mma.shape[0]) + 0.5, minor=False) # mma.shape[0] = input seq \n",
    " \n",
    "    # without this I get some extra columns rows\n",
    "    # http://stackoverflow.com/questions/31601351/why-does-this-matplotlib-heatmap-have-an-extra-blank-column\n",
    "    ax.set_xlim(0, int(mma.shape[1]))\n",
    "    ax.set_ylim(0, int(mma.shape[0]))\n",
    " \n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    " \n",
    "    # source words -> column labels\n",
    "    ax.set_xticklabels(source_labels, minor=False)\n",
    "    # target words -> row labels\n",
    "    ax.set_yticklabels(target_labels, minor=False)\n",
    " \n",
    "    plt.xticks(rotation=45)\n",
    " \n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def read_plot_alignment_matrices(source_labels, target_labels, alpha):\n",
    " \n",
    "    mma = alpha.cpu().data.numpy()\n",
    " \n",
    "    plot_head_map(mma, target_labels, source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The attention tensor does not have the correct number of dimensions. Make sure you set output_attentions=True when initializing your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_753016/4086457787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#read_plot_alignment_matrices(input_str, output_str, attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhead_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/bertviz/head_view.py\u001b[0m in \u001b[0;36mhead_view\u001b[0;34m(attention, tokens, sentence_b_start, prettify_tokens, layer, heads, encoder_attention, decoder_attention, cross_attention, encoder_tokens, decoder_tokens, include_layers)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_layers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0minclude_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msentence_b_start\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             attn_data.append(\n",
      "\u001b[0;32m~/venv/lib/python3.8/site-packages/bertviz/util.py\u001b[0m in \u001b[0;36mformat_attention\u001b[0;34m(attention, layers, heads)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# 1 x num_heads x seq_len x seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             raise ValueError(\"The attention tensor does not have the correct number of dimensions. Make sure you set \"\n\u001b[0m\u001b[1;32m     12\u001b[0m                              \"output_attentions=True when initializing your model.\")\n\u001b[1;32m     13\u001b[0m         \u001b[0mlayer_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The attention tensor does not have the correct number of dimensions. Make sure you set output_attentions=True when initializing your model."
     ]
    }
   ],
   "source": [
    "attn = state_dict['explanation.encoder.layer.11.output.LayerNorm.weight']\n",
    "attn.shape\n",
    "head_view(attn, encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = \"the sears tower in chicago is 145 ##0 feet tall . the john hancock center in chicago is 112 ##7 feet tall . suppose you are asked to build a small - scale replica of each . if you make the sears tower 3 meter tall , what would be the approximate height of the john hancock replica ? round your answer to the nearest hundred ##th .\"\n",
    "encoded_input = tokenizer.encode(input_str)\n",
    "len(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str = \"the height of the sears tower\"\n",
    "encoded_output = tokenizer.encode(output_str)\n",
    "len(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 1,\n",
       " 'batch_size': 16,\n",
       " 'beam_for_equation': 3,\n",
       " 'beam_for_explanation': 5,\n",
       " 'dataset': '/home/bydelta/SimpleFESTA/resource/dataset/pen.json',\n",
       " 'learner': {'model': 'SWAN_P1',\n",
       "  'encoder': 'google/electra-base-discriminator',\n",
       "  'equation': {'hidden_dim': 0, 'intermediate_dim': 0, 'layer': 6, 'head': 0},\n",
       "  'explanation': {'encoder': 'google/electra-base-discriminator',\n",
       "   'shuffle': True}},\n",
       " 'resource': {'num_gpus': 1.0, 'num_cpus': 1.0},\n",
       " 'experiment': {'dev': {'split_file': '/home/bydelta/SimpleFESTA/resource/experiments/pen/dev',\n",
       "   'period': 100},\n",
       "  'train': {'split_file': '/home/bydelta/SimpleFESTA/resource/experiments/pen/train'},\n",
       "  'test': {'split_file': '/home/bydelta/SimpleFESTA/resource/experiments/pen/test',\n",
       "   'period': 500}},\n",
       " 'grad_clip': 10.0,\n",
       " 'optimizer': {'type': 'lamb',\n",
       "  'lr': 0.00176,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'debias': True},\n",
       " 'scheduler': {'type': 'warmup-linear',\n",
       "  'num_warmup_epochs': 10.0,\n",
       "  'num_total_epochs': 500},\n",
       " 'window': 3}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = data_path / 'dataset' / 'pen.json'\n",
    "\n",
    "KEY_DATASET = 'dataset'\n",
    "KEY_SEED = 'seed'\n",
    "\n",
    "exp_base = {\n",
    "        KEY_DATASET: str(dataset_file.absolute()),\n",
    "        KEY_SEED: config['seed']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check, test_results = run_model_for_attention(chpt_path, **exp_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
